\chapter{Задача тематического моделирования и методы решения}


\section{Постановка задачи}

Метод тематического моделирования (topic modeling) можно отнести к широкому классу методов обработки текстовых коллекций, основанных на явном или неявном представлении связей между документами и составляющими их терминами в матричном виде (матрица частот встречаемости терминов в документах, которая может быть очень большой, разреженной и шумной) и последующей обработки такой матрицы с целью получения приближенного представления, существенно меньшего по размеру, менее шумного и сохраняющего (а, по возможности, эксплицирующего) полезную информацию, содержащуюся в исходной матрице. Метод тематического моделирования позволяет описать текстовую коллекцию в виде произведения двух матриц, где одна матрица может интерпретироваться как описывающая документы в виде дискретного распределения над фиксированным набором скрытых тем (topic), а вторая как описывающая темы в виде дискретного распределения над терминами. Таким образом, результатом обработки являются плотные (dense) векторные репрезентации документов и описывающих их тем, которые в свою очередь могут быть использованы в большом числе прикладных задач. 

Формально, рассматривается коллекция текстовых документов $D$, множество входящих в них терминов (слов или словосочетаний) $W$. Каждый документ $d \in D$ рассматривается как последовательность терминов $w_1, \ldots, w_{n_d}$ из словаря $W$, где $n_d$ -- количество терминов в документе $d$. Множество документов может быть рассмотрено как случайная и независимая выборка троек $(w_i, d_i, t_i)$, $i = 1, \ldots, n$ из дискретного распределения $p(w, d, t)$ на конечном вероятностном пространстве $W \times D \times T$, где $t \in T$ -- латентная переменная, представляющая тему. \parencite{vorontsov2015topic}

Метод тематического моделирования опирается на следующие допущения:
\begin{enumerate}
  \item вхождение термина в документ некоторым образом связано с темой;
  \item документы рассматриваются как неупорядоченные наборы терминов, порядок слов и грамматичность предложений игнорируются (гипотеза ``мешка слов'');
  \item порядок текстов в коллекции не важен (гипотеза ``мешка документов'');
  \item встречаемость терминов в документах зависит от темы, но не зависит от документа, т.е. описывается общим для всех документов распределением $p(w|t)$ (гипотеза условной независимости). Это допущение имеет следующие эквивалентные представления: $p(w|d,t) = p(w|t)$, $p(d|w,t) = p(d|t)$, $p(d, w|d) = p(d|t)p(w|t)$.
\end{enumerate}

Порождение документов на основе множества латентных тем может быть формализовано с помощью следующей генеративной модели: $p(w|d) = \sum_{t \in T}p(w|t)p(t|d)$. Эта модель выражает вероятность появления термина в документе через известные распределения $p(w|t)$ и $p(t|d)$. Построение тематической модели является обратной задачей: здесь по известной текстовой коллекции $D$ требуется найти распределения $p(w|t)$ и $p(t|d)$. В общем виде задача определяется как оптимизационная задача стохастического матричного разложения, состоящая в нахождении двух матриц $\Phi = (\phi_{wt})_{W \times T}$ (матрицы терминов тем) и $\Theta = (\theta_{td})_{T \times D}$ (матрицы тем документов), таких что матрица частот терминов в документах $F=(f_{wd})_{W \times D}, f_{wd} = n_{dw} / n_d$ аппроксимируется произведением $F \approx \Phi \Theta$. При этом матрицы $\Phi$ и $\Theta$ рассматриваются в качестве параметров модели, и все три матрицы $F$, $\Phi$ и $\Theta$ являются \textit{стохастическими}, т.е. столбцы $f_d, \phi_t$ и $\theta_d$ представляют собой дискретные распределения (матрицы имеют неотрицательные компоненты и нормированы по столбцам).

В общем виде задача построения тематической модели является некорректно поставленной, т.к. допускает бесконечное множество решений. Для получения устойчивого решения требуется введение ряда дополнительных критериев и ограничений (например, предположение о том, что столбцы $\theta_d$ и $\phi_t$ являются случайными векторами, порождаемыми распределением Дирихле, в модели латентного размещения Дирихле). Число и разнообразие таких критериев, а также различные варианты используемых методов оценки параметров, определяют значительное число вариантов практических реализаций данного подхода. В числе особенностей метода, имеющих важное значение для практики, следует отметить произвольный выбор числа извлекаемых тем пользователем (хотя существуют методы, позволяющие устранять коррелированные и малоинформативные темы), возможные затруднения с интерпретируемостью извлекаемых тем.

Приложения тематического моделирования включают информационный поиск (information retrieval), в особенности разведочный поиск (exploratory search), выявление трендов в новостях и научных публикациях, анализ социальных сетей, классификацию и категоризацию документов, суммаризацию, сегментацию текстов, тегирование веб-страниц и новостей, обнаружение спама, разработку рекомендательных систем и пр. \parencite{vorontsov2015topic}


\section{Методы оценки качества результатов}

Методы оценки качества результатов тематического моделирования можно разделить на внутренние (intrinsic) и внешние (extrinsic). В первом случае речь идет об оценке непосредственно модели с точки зрения её характеристик, осуществляемой по исходной текстовой коллекции. В числе метрик такого рода: перплексия (perplexity), разреженность матриц $\Phi$ и $\Theta$ (количество компонентов, близких к нулю), чистота и контрастность тем, когерентность наиболее вероятных слов темы (общепринятая мера интерпретируемости темы), доля фоновых слов и др. Во втором случае оценка осуществляется с точки зрения качества целевой системы, в которой результаты тематического моделирования используются как составной компонент (например, оценка качества информационного поиска с привлечением ассессоров).

Далее кратко опишем распространенные внутренние оценки.

\subsection*{Перплексия}

Перплексия (perplexity) традиционно используется для характеристики языковых моделей\footnote{Языковая модель -- это распределение $p(w), w \in L \subseteq \Sigma^*$, где $\Sigma^*$ -- множество всевозможных последовательностей букв из конечного алфавита $\Sigma$.}
и характеризует несоответствие модели $p(w)$ наблюдаемому слову $w$. Определяется через логарифм функции правдоподобия и применительно к задаче тематического моделирования формулируется следующим образом: $\mathcal{P}(D; p) = exp(-\frac{1}{n}L(\Phi, \Theta)) = exp(-\frac{1}{n}\sum_{d \in D}\sum_{w \in W}n_{dw}ln\,p(w|d))$, где $n$ -- число терминов в коллекции. Модель $p$ тем лучше предсказывает термины в документах коллекции, чем меньше перплексия.

При обучении тематической модели на всей коллекции и вычислении перплексии на той же обучающей выборке, перплексия оказывается занижена (т.е. оказывается лучше, чем должна быть) в силу переобучения. Чтобы этого избежать, рассматривают перплексию контрольной выборки (hold-out perplexity), т.е. считают на части коллекции, не использовавшейся для обучения (например, отбирая случайным образом десятую часть документов из исходной коллекции).

Перплексия как метрика обладает определенными недостатками, т.к. её значение зависит не только от качества модели, но и от длины документов, размера словаря и т.п.

\subsection*{Когерентность}

Когерентность (согласованность) темы определяется на основе поточечной взаимной информации (pointwise mutual information) и характеризует совместную встречаемость наиболее вероятных терминов определенной темы в документах коллекции (использовавшейся для обучения или сторонней).

$PMI(t) = \sum_{i=1}^{k-1}\sum_{j=i+1}^{k}log\frac{N(w_i, w_j)}{N(w_i)N(w_j)}$, где $w_i$ - i-й термин в порядке убывания $\phi_{wt}$, $N(w)$ -- число документов, содержащих термин $w$, $N(w, w')$ -- число документов, в которых термины $w$ и $w'$ встречаются в окне фиксированного размера, $k$ -- ограничение на число наиболее вероятных терминов, используемых для расчета, на практике обычно равно 10.

Средняя когерентность тем применяется в качестве меры интерпретируемости тематической модели.

\subsection*{Разреженность}

Разреженность -- доля ненулевых элементов в матрицах $\Phi$ и $\Theta$ (либо только по предметным темам, если в модели различаются предметные и фоновые темы).

\subsection*{Показатели интерпретируемости темы на основе лексического ядра}

Множество слов, отличающих одну тему от остальных, называют её лексическим ядром. Наличие ядра позволяет характеризовать тему как интерпретируемую.

Ядро темы $W_t = \{w \in W \; | \; p(t|w) > 0,25\}$, где $p(t|w) = \phi_{wt}\frac{n_t}{n_w}$. Показатели интерпретируемости темы:
\begin{enumerate}
    \item чистота $\Sigma_{w \in W_t}p(w|t)$ (чем выше, тем лучше)
    \item контрастность $\frac{1}{|W_t|\Sigma_{w \ in W_t}p(t|w)}$ (чем выше, тем лучше)
    \item мощность ядра $|W_t|$ (оптимум вблизи $\frac{|W|}{|T|}$)
\end{enumerate} 

Соответствующие показатели для всей модели считаются как среднее по всем предметным темам.

\subsection*{Доля фоновых слов}

$\mathcal{B} = \frac{1}{n}\Sigma_{d \in D}\Sigma_{w \in W}\Sigma_{t \in T}n_{dw}p(t|d,w)$, принимает значения в диапазоне $[0, 1]$, экстремальные значения говорят о вырожденности модели.


\section{Основные традиционные методы (pLSA, LDA)}

Основные традиционные методы: байесовское обучение, LSA, pLSA, LDA. Обзор основных реализаций (Gensim, Vowpal Wabbit, BigARTM и др.)

\section{Аддитивная регуляризация для тематических моделей (ARTM)}

Понятие регуляризации. Аддитивная регуляризация. ARTM. Характеристика метода. Технические аспекты (отсутствие автоматической процедуры подбора регуляризаторов и пр.). Реализация метода в библиотеке BigARTM.

\section{Нейросетевые методы. BERTopic}

Нейросетевые методы. Отказ от допущения ``мешка слов'', попытки учесть контекстные значения. Краткая характеристика основных механизмов трансформерных моделей: вектроные репрезентации значений слов, энкодер-декодер архитектура, механизм внимания, KVQ-формализм, понятие языковой модели и маскированной языковой модели (MLM). Понятие предобученной модели и transfer learning. BERT как энкодер, способный учитывать контекстные значения слов. Тематическое моделирование с помощью архитектуры BERTopic.

\section{Состязательное тематическое моделирование}

Состязательные сети (adversarial). Тематическое моделирование средствами adversarial topic modeling (ATM).



\chapter{Автоматическое именование тем}

\section{Характеристика проблемы интерпретируемости}

Характеристика проблемы интерпретируемости тем (не во всех downstream задачах это является проблемой). В тематическом моделировании документы представляются как вектора, где размерностями выступают темы, а значениями (коэффициентами) по соответствующим размерностям -- вероятности тем. Т.о. это представление является интерпретируемым (в отличие от document embeddings в doc2vec и аналогичных подходах). Однако, число тем и их содержание уже не являются непосредственно интерпретируемыми: число тем задается пользователем (ср. k-NN кластеризация), темы описываются распределением над термами.

Задача интерпретации тем пользователем первоначально решалась либо представлением темы в виде списка наиболее важных слов, либо путем её аннотирования вручную. Впервые задача автоматического именования тем была поставлена в работе \parencite{mei2007automatic} и в дальнейшем стала важной подзадачей направления тематического моделирования. В данном разделе рассмотрим основные подходы к её решению.

\section{Mei, Shen, Zhai. Automatic labeling of multinomial topc models. KDD, 2007.}

Первая работа, в которой ставится задача автоматического именования тем -- \parencite{mei2007automatic}. Здесь предлагается формальная постановка задачи, рассматриваются интуитивные требования к выбору наименований тем и разрабатываются формальные критерии, отражающие различные аспекты интерпретируемости. В этой работе предлагается двухэтапный подход, ставший в дальнейшем основным при решении задачи автоматического именования тем, состоящий в генерации набора  наименований-кандидатов и их последующего ранжирования с целью отбора наилучших по ряду критериев, включающих понятность для пользователя, способность отражать значение темы и возможность отличать одну тему от остальных, опираясь на её наименование.

В тематическом моделировании обнаруживаемые темы представляются в виде мультиномиального распределения на множестве слов (т.е. в виде униграммной языковой модели). Ключевая идея подхода, предлагаемого в статье, состоит в представлении возможных наименований также в виде мультиномиального распределения на множестве слов. Благодаря этому оказывается возможным оценивать сходство двух этих распределений и таким образом свести задачу выбора наилучших наименований к оптимизационной задаче, основанной на минимизации расстояния Кульбака-Лейблера между распределениями темы и наименования.

Среди возможных вариантов выбора кандидатов для наименований, включающих отдельные термины, фразы или предложения, авторы останавливаются на использовании фраз, т.к. фразы отличаются большей согласованностью, чем отдельные термины, достаточно компактны по сравнению с предложениями, но при этом способны отражать значение темы. Кроме того, было замечено, что при ручной разметке, аннотаторы также используют коротки фразы для описания значения тем.

Предлагается следующая формальная постановка задачи автоматического наименования тем:

Тематическая модель $\theta$ текстовой коллекции $\mathcal{C}$ -- это вероятностное распределение на множестве слов $\{p(w|\theta)\}_{w \in V}$, где $V$ -- словарь. Ясно, что $\sum_{w \in V}p(w|\theta) = 1$.

Наименование $l$ для темы $\theta$ -- это осмысленная последовательность слов, отражающая скрытое значение $\theta$.

Оценка релевантности наименования темы $s(l, \theta)$ является характеристикой семантичекого сходства между наименованием и темой. Наименование $l_1$ лучше наименования $l_2$, если $s(l_1, \theta) > s(l_2, \theta)$.

\textit{Задача наименования отдельной темы} $\theta$, извлеченной из текстовой коллекции, состоит в определении множества наименований-кандидатов $L = \{l_1, \ldots, l_m\}$, разработке функции оценки релевантности $s(l_i, \theta)$ и нахождении подмножества $L_\theta = \{l_{\theta, 1}, \ldots, l_{\theta, n}\}$ из $n$ наименований, имеющих наибольшую оценку релевантности  для $\theta$.

Задача наименования отдельной темы обобщается на \textit{множество тем} следующим образом. Пусть $\Theta = \{\theta_1, \ldots, \theta_k\}$ -- множество из $k$ тем, $L = \{l_1, \ldots, l_m\}$ -- множество наименований-кандидатов. Требуется отобрать подмножество из $n_i$ наименований, $L_{\theta_i} = \{l_{\theta_i, 1}, \ldots, l_{\theta_i, n}\}$ для каждой темы $\theta_i \in \Theta$ .

В некоторых практических сценариях применения тематического моделирования набор наименований-кандидатов может быть заранее определен (например, задаваться онтологией). Однако, в общем случае предполагается, что такой набор заранее неизвестен. Его задание опирается на использование некоторой референсной текстовой коллекции, которая может быть внешней по отношению к набору документов, для которых создается тематическая модель, либо совпадать с ним.\footnote{В качестве примера внешней референсной коллекции можно привести статьи с конференции по определенной тематике.}

Общая процедура нахождения наилучших наименований для тем включает три этапа:
\begin{enumerate}
    \item создается набор осмысленных наименований-кандидатов 
    \item разрабатывается функция оценки релевантности наименований относительно темы
    \item производится отбор наименований для удовлетворения интуитивных критериев качества наименования, таких как способность различение тем и адекватное отражение семантики отдельной темы. 
\end{enumerate}

В качестве методов порождения набора наименований-кандидатов рассматриваются неглубокий синтаксический анализ (chunking) и статистические методы отбора n-грамм. Первый метод основан на применении специальных программных решений, извлекающих именные группы с опорой на частеречную разметку, определенный грамматический формализм и т.п. Эти решения сложны, могут требовать дополнительных обучающих данных и доступны для ограниченного числа языков. Второй метод опирается на отбор частотных n-грамм из референсной текстовой коллекции в предположении, что такие n-граммы обычно представляют собой осмысленные фразы. Отбор производится с помощью статистических метрик  (например, взаимной информации) или с помощью методов статистической проверки гипотез ($\chi^2$, $t$-тест Стьюдента). Этот способ применим к текстовым коллекциям в любых предметных областях, однако показывает хорошие результаты только для биграмм.

Для оценки семантической релевантности наименований-кандидатов извлекаемым темам предлагаются две функции.

Функция оценки релевантности \textit{нулевого порядка} позволяет оценивать релевантность наименования теме без использования референсной текстовой коллекции. Обозначим фразу-кандидата $l = u_0 u_1 \ldots u_m$, где $u_i$ -- слово. Оценка $score = log \, \frac{p(l|\theta)}{p(l)} = \sum_{0 \leqslant i \leqslant m} log \, \frac{p(u_i|\theta)}{p(u_i)}$, где $u_i$ предполагаются независимыми. Интуитивный смысл данной функции: фраза, содержащая более важные слова по распределению темы (т.е. с большим $p(w|\theta)$), является хорошим наименованием для данной темы. Здесь вероятность слова $p(u_i)$ в знаменателе требуется для компенсации смещения, связанного с обучающей текстовой коллекцией, и может оцениваться по вспомогательной коллекции или быть принята за равномерную. То есть, с помощью данной функции фраза оценивается на основе правдоподобия её порождения тематической моделью $\theta$ по сравнению с некоторым вспомогательным распределением.

Функция оценки релевантности \textit{первого порядка} основана на представлении наименования с помощью распределения над словами исходной текстовой коллекции, благодаря чему оно может сравниваться с распределением темы по расстоянию Кульбака-Лейблера. Пусть $l$ -- наименование, $\{p(w|l)\}$ -- мультиномиальное распределение, ассоциированное с $l$. Тогда расстояние Кульбака-Лейблера $D(\theta||l)$ отражает то, насколько хорошо $l$ описывает $\theta$.  $D(\theta||l) = 0$ в случае, если эти распределения совпадают. Построение распределения $\{p(w|l)\}$ требует использования референсной текстовой коллекции $\mathcal{C}$, выступающей в качестве контекста. Функция оценки релевантности наименования $l$ относительно темы $\theta$ определяется как отрицательное расстояние Кульбака-Лейблера между распределениями $\{p(w|\theta)\}$ и $\{p(w|l)\}$. За счет введения контекста $\mathcal{C}$, функция оценки релевантности может быть преобразована следующим образом:

$score(l, \theta) =$

$= -D(\theta||l) =$

$= -\sum_{w}p(w|\theta)log\,\frac{p(w|\theta)}{p(w|l)} =$

$= -\sum_{w}p(w|\theta)log\,[\frac{p(w|\mathcal{C})}{p(w|l,\mathcal{C})}\cdot  \frac{p(w|\theta)}{p(w|\mathcal{C})}\cdot\frac{p(w|l,\mathcal{C})}{p(w|l)}] =$

$= -\sum_{w}p(w|\theta)log\,\frac{p(w|\mathcal{C})}{p(w|l,\mathcal{C})} -\sum_{w}p(w|\theta)log\,\frac{p(w|\theta)}{p(w|\mathcal{C})} -\sum_{w}p(w|\theta)log\,\frac{p(w|l,\mathcal{C})}{p(w|l)} =$

$= \sum_{w}p(w|\theta)\,PMI(w,l|\mathcal{C}) - D(\theta||\mathcal{C}) + Bias(l, \mathcal{C})$

\noindent Здесь второй компонент представляет собой расстояние Кульбака-Лейблера между темой и \textit{контекстом}. Т.к. он не зависит от наименований, в функции оценки релевантности наименований он может быть опущен. Третий компонент может рассматриваться как смещение (bias) при использовании контекста для оценки семантической релевантности $l$ и $\theta$. Наконец, первый компонент представляет собой матожидание поточечной взаимной информации (PMI) между $l$ и терминами темы при заданном контексте: $E_\theta(PMI(w,l|\mathcal{C}))$.

При отсутствии априорных данных о смещении, определяемом контекстом (т.е. референсной текстовой коллекцией), функция оценки релевантности может быть редуцирована до $s(l,\theta) = E_\theta(PMI(w,l|\mathcal{C}))$. Значения $E_\theta(PMI(w,l|\mathcal{C}))$ могут считаться независимо от тем. В случае, если определенное слово из обучающей текстовой коллекции не содержится в референсной коллекции, $PMI(w,l|\mathcal{C})$ не определена. Тогда соответствующее слагаемое может полагаться равным нулю, либо может применяться та или иная стратегрия сглаживания (например, сглаживание Лапласа). 

Данная функция берется в качестве искомой функции оценки релевантности первого порядка и используется для ранжирования наименований-кандидатов. Интуитивно, она тем выше ранжирует наименование, чем сильнее его семантическая связь с наиболее важными (вероятными) словами темы.

Заключительная часть процедуры нахождения наилучших наименований тем состоит в отборе таких наименований, которые удовлетворяют интуитивным критериям качества. 

Во-первых, необходимо, чтобы наименования максимально отражали семантическую информацию конкретной темы. Поскольку для описания темы может применяться более одной фразы, необходимо последовательно максимизировать информативность каждого следующего наименования с учетом уже выбранных. Это достигается путем поочередного отбора наименований из числа кандидатов, при этом на каждом шаге максимизируется критерий максимальной маржинальной релевантности (maximal marginal relevance, MRR):

\[\hat{l} = \argmax_{\l \in L\setminus S} \, [\lambda Score(l, \theta) - (1-\lambda)\max_{l' \in S} Sim(l', l)], \]

\noindent где $S$ -- множество уже отобранных наименований, $Sim(l', l) = -D(l'||l) = -\Sigma_w p(w|l') log \frac{p(w|l')}{p(w|l)}$, $\lambda$ -- (гипер)параметр.

Во-вторых, требуется отбирать наименования, способные наилучшим образом различать темы в случае, если наименования назначаются более чем одной теме, т.к. в этом случае наименование с высокой оценкой одновременно для нескольких тем оказывается бесполезно. Т.е. необходимо обеспечить высокую оценку для одной темы и низкую для остальных. Это достигается следующим образом:

\[Score'(l, \theta_i) = Score(l, \theta_i) - \mu\,Score(l, \theta_{1,\ldots, i-1,i+1, k}),\]

\noindent где $\mu$ -- параметр, регулирующий степень различающей способности критерия, $Score(l, \theta_{1,\ldots, i-1,i+1, k}) \approx (1 + \frac{\mu}{k-1})E_{\theta_i}(PMI(w,l|\mathcal{C})) - \frac{\mu}{k-1}E_{\theta_j}(PMI(w,l|\mathcal{C}))$. Используя эту функцию, можно добиться необходимого различения тем.


\section{Mirzagitova, Mitrofanova. Automatic assignment of labels in topic modelling for Russian corpora. 2016}

Подход к автоматическому именованию тем, разрабатываемый в данной работе, основан на использовании графового представления связей между терминами. Алгоритм двухэтапный: сначала производится порождение кандидатов осуществляется с помощью алгоритма PageRank и набора морфологических фильтров, затем производится ранжирование и отбор. Работа опирается на предшествующие разработки в области именования тем с использованием графовых методов, описанные в \parencite{aletras2014labelling}. Особенностью рассматриваемой работы является обработка русского языка и использование специализированного русскоязычного корпуса для оценки метода.

На этапе порождения кандидатов из списка слов отбираются 10 наиболее вероятных слов определенной темы. Для каждого из этих слов выполняется запрос в поисковой системе. На странице поисковой выдачи отбираются 30 заголовков, начиная с первой позиции, которые объединяются в один текст. Этот текст подвергается токенизации и лемматизации. Из полученных словоупотреблений строится граф, в котором леммы располагаются в вершинах графа, ребра проставляются между теми леммами, которые встречаются в тексте в окне размера [-2, +2]. Ребра взвешиваются тремя способами: 
\begin{itemize}
    \item[(I)] все веса равны 1; 
    \item[(II)] веса равны частоте совместной встречаемости соответствующих лемм в пределах данного текста;
    \item[(III)] веса равны поточечной взаимной информации (PMI), рассчитанной по русскоязычному разделу Википедии.
\end{itemize} 
\noindent Затем к полученному взвешенному графу применяется PageRank (PageRangk вычисляется для каждой вершины). Таким образом, в результирующем графе вершинам и ребрам присваиваются веса, причем вершины (леммы) взвешиваются по ``важности'', а ребра (биграммы) взвешиваются по ``семантической связанности''. Из полученного графа отбираются n-граммы (подграфы) по следующим морфологическим шаблонам:
\begin{itemize}
    \item[] прилагательное + существительное
    \item[] существительное + существительное в родительном падеже
    \item[] существительное + предлог + существительное
    \item[] существительное + союз + существительное
    \item[] и т.п.
\end{itemize} 
Контактирующие фразы конкатенируются и добавляются в качестве дополнительных кандидатов.

Для этапа ранжирования рассматриваются три ранжирующих метрики
\begin{itemize}
    \item[(A)] сумма весов слов во фразе-кандидате  
    \item[(B)] сумма весов, отнормированная по длине фразы
    \item[(C)] сумма коэффициентов, домноженная на $1 + \frac{1}{i}$, где $i$ -- ранг слова, отобранного из числа десяти наиболее вероятных терминов по распределению темы, включенного в исходный запрос.
\end{itemize} 

Для оценки метода использовался корпус русскоязычных энциклопедических текстов о лингвистике, размером 1900 докуменов, 1,3 млн. словоупотреблений. Из корпуса были удалены стоп-слова, произведена лемматизация с помощью библиотеки pymorphy2, результарующая обучающая текстовая коллекция содержит около 800 тыс. словоупотреблений. Для извлечения тем использовалась реализация латентного размещения Дирихле из библиотеки scikit-learn. Производилось извлечение двадцати тем. Темам были автоматически присвоены наименования в соответствии с описанной процедурой. Результаты были размечены вручную (оценки релевантности от 0 до 3, где 0 -- нерелевантно). В качестве baseline использовалось наиболее вероятное слово по распределению темы. 

Результаты оценки: baseline 1.03, лучший вариант A-III (ранжирование на основе простой суммы весов, взвешивание графа по PMI на основе Википедии) 2.07, все остальные варианты лучше baseline. При этом схема A-II (использование частоты совместной встречаемости в текстах исходной обучающей коллекции) также показала приемлемый результат, при этом данная схема вычислительно проще и не требует использования внешнего корпуса. 


\section{Lishan Cui, Xiuzhen Zhang, Amanda Kimpton, Daryl D'Souza. Automatic labelling of topics via analysis of user summaries. 2016}

В данной работе представлен доход к извлечению слов и осмысленных фраз, используемых в задаче автоматического именования тем, из внешних пользовательских обзоров и комментариев. Пользовательские обзоры, представленные на сайтах Yahoo! Answers, Stack Overflow, или пользовательские комментарии к новостям, описаниям товаров в интернет-магазинах и др., отличаются высокой релевантностью относительно связанных с ними документов, тогда как генерация наименований-кандидатов по таким внешним источникам, как Википедия, не всегда приводит к осмысленным результатам для текстов узкой предметной области.

Предлагаемая процедура автоматического именования тем включает следующие шаги:
\begin{itemize}
    \item с помощью парсера для грамматик зависимостей с последующей фильтрацией по критерию частотности для отсечения шума из пользовательских обзоров генерируются осмысленные фразы, которые далее используются в качестве кандидатов для наименований тем;
    \item на основе расстояния Кульбака-Лейблера строится ранжирующая функция для оценки семантической ассоциации между темой и фразами-кандидатами, причем темы и фразы-кандидаты представляются как распределения над документами, а не словами.
\end{itemize} 

На первом шаге осуществляется обработка коллекции пользовательских обзоров для формирования множества кандидатов. Непосредственно отбираются фразы длиной до трех слов и встречающиеся в корпусе не менее четырех раз (эмпирическое наблюдение: такие короткие фразы обычно представляют собой отдельные существительные или именные группы). Предложения длиннее трех слов обрабатываются с помощью стенфордского парсера для грамматик зависимостей (Stanford dependency parser). Из полученной синтаксической структуры выбираются подструктуры, содержащие существительное в качестве вершины и зависимые узлы, в линейной последовательности непосредственно примыкающие к вершине, т.к. такие подструктуры с большой вероятностью представляют собой именные группы. Дополнительно отфильтровывается шум по порогу частотности (количество употреблений на число пользовательских обзоров <1\%).

Формальная постановка задачи автоматического именования в целом соответствует постановке из работы \parencite{mei2007automatic}, однако имеется важное отличие. Так как наименование-кандидат в рассматриваемом подходе всегда ассоциировано с документом, то и для $l$, и для $\theta$ оказывается возможным определить распределение над документами (одними и теми же). Поэтому функцию оценки релевантности можно задать как $s(l, \theta) = -D_{KL}(P_\theta||P_l) = -\Sigma_{d \in D}P_\theta(i)\,ln\frac{P_\theta(d)}{Q_l(d)}$, где $P_\theta$ -- мультиномиальное распределение на множестве документов для темы $\theta$, $Q_l$ -- мультиномиальное распределение на множестве документов для кандидата $l$, $d \in D$ -- документ. По ранжирующей функции $s(l, \theta)$ отбирается несколько кандидатов с максимальной оценкой (в данной работе -- два), которые используются в качестве искомого наименования темы.

Экспериментальная оценка метода осуществлялась по корпусу, сформированному на основе веб-форума о медицинских услугах Patient Opinion Australia. Корпус включает 623 текста и 593 пользовательских обзора, средняя длина обзора составляет 4 слова, максимальная длина обзора -- 29 слов. С помощью непераметрического LDA было извлечено 50 тем, 9 тем отфильтрованы как некогерентные (фильтрация осуществлялась на основе наличия частотных фраз, которые были включены в тему во фрагментарном виде). Оценка выполнялась ассессорами по шкале от 0 (нерелевантно) до 3 (очень хорошо). Предложенный метод сравнивался с альтернативами: 
\begin{itemize}
    \item использование в качестве наименования десяти наиболее вероятных слов темы;
    \item использование в качестве наименования десяти вероятных слов с их переранжированнием на основе частоты встречаемости в пользовательских обзорах;
    \item использование в качестве наименования одной тысячи наиболее частотных биграмм из документов.
\end{itemize} 
\noindent Предложенный метод продемонстрировал оценку 1.815, альтернативные варианты -- оценку в диапазоне от 1.32 до 1.36.

 






\chapter{Автоматическое определение однородности}

\section{Метрики однородности корпуса и темы}

Метрики однородности корпуса (corpus homogeneity) vs. метрики однородности темы (topic homogeneity). Связь метрик однородности корпуса и метрик качества тематического моделирования на примере perplexity. Использование тематических признаков (topical features) слов в задачах снятия лексической неоднозначности (WSD) и др.

\section{BoW}

Метрики однородности корпуса на основе частот слов (статистики на bag-of-words)

\section{Thesauri}

Метрики однородности корпуса на основе онтологий/тезаурусов – анализ родственных слов в иерархии
семантических понятий

\section{Embeddings}

Метрики однородности корпуса на основе расстояний между эмбеддингами текстов

\section{Enthropy}

Метрики однородности корпуса на основе энтропии
